# Test configuration for Diffusion-DPO training

# Model Configuration
model_name_or_path: "nieshen/SMDM" # HF Repo ID
checkpoint_filename: "mdm_safetensors/mdm-170M-100e18.safetensors" # Specific checkpoint file within the repo
model_size_M: 170 # Model size in Millions for config lookup

# Data Configuration
preference_data_path: "data/preference_data/synthetic_prefs.jsonl" # Path to synthetic test dataset
max_length: 512 # Reduced max length for testing

# Training Configuration
output_dir: "diffusion_dpo_test_output" # Directory for test run output
learning_rate: 1.0e-6 # Reduced LR for test
per_device_train_batch_size: 1
gradient_accumulation_steps: 1 # No accumulation for quick test
num_train_epochs: 1
max_train_steps: 10 # Limit to only 10 steps for testing
lr_scheduler_type: "constant" # Simple scheduler for test
num_warmup_steps: 0
weight_decay: 0.0
seed: 42

# DPO Configuration
beta: 0.1
diffusion_steps: 5 # Reduced diffusion steps for faster testing

# Optimization Configuration
use_mixed_precision: "fp16" # Keep fp16 for potential memory savings
gradient_checkpointing: false # Disable GC for faster test, assuming 170M model fits

# Logging and Saving
save_steps: 5 # Save frequently during test
logging_steps: 1 # Log every step during test
checkpointing_steps: null # Don't save full checkpoints during this short test
resume_from_checkpoint: null

